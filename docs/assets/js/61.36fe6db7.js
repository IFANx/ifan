(window.webpackJsonp=window.webpackJsonp||[]).push([[61],{335:function(_,v,o){"use strict";o.r(v);var e=o(14),r=Object(e.a)({},(function(){var _=this,v=_._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[v("h2",{attrs:{id:"jvm"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#jvm"}},[_._v("#")]),_._v(" JVM")]),_._v(" "),v("h3",{attrs:{id:"_1-类加载流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-类加载流程"}},[_._v("#")]),_._v(" 1.类加载流程")]),_._v(" "),v("p",[_._v("（加载-验证-准备-解析-初始化-使用-卸载）")]),_._v(" "),v("h3",{attrs:{id:"_2-java类加载机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-java类加载机制"}},[_._v("#")]),_._v(" 2.java类加载机制")]),_._v(" "),v("p",[_._v("（双亲委派模型以及SPI机制）")]),_._v(" "),v("h3",{attrs:{id:"_3-bean的生命周期"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-bean的生命周期"}},[_._v("#")]),_._v(" 3.Bean的生命周期")]),_._v(" "),v("p",[_._v("Bean 在 Spring（IoC）中从创建到销毁的整个过程。")]),_._v(" "),v("h3",{attrs:{id:"_4-java运行时内存结构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_4-java运行时内存结构"}},[_._v("#")]),_._v(" 4.java运行时内存结构")]),_._v(" "),v("h3",{attrs:{id:"_5-aqs-abstractqueuedsynchronizer"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5-aqs-abstractqueuedsynchronizer"}},[_._v("#")]),_._v(" 5.AQS（AbstractQueuedSynchronizer）")]),_._v(" "),v("h2",{attrs:{id:"mysql-redis相关"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql-redis相关"}},[_._v("#")]),_._v(" MySQL & Redis相关")]),_._v(" "),v("p",[_._v("mysql server层具有一个查询缓存，innodb也有一个buffer pool称为缓存池。")]),_._v(" "),v("p",[_._v("在 MySQL 启动的时候，"),v("strong",[_._v("InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的"),v("code",[_._v("16KB")]),_._v("的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页")]),_._v("。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。")]),_._v(" "),v("p",[_._v("Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等等。")]),_._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/bufferpool%E5%86%85%E5%AE%B9.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0",alt:"img"}})]),_._v(" "),v("blockquote",[v("p",[_._v("Undo 页是记录什么？")])]),_._v(" "),v("p",[_._v("开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。")]),_._v(" "),v("p",[_._v("buffer pool实际也在内存中，有了Buffer Pool 后：buffer pool中是一个一个数据页，页为单位进行IO")]),_._v(" "),v("ul",[v("li",[_._v("当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。")]),_._v(" "),v("li",[_._v("当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。")])]),_._v(" "),v("h3",{attrs:{id:"_6-mysql事务-三个日志-分布式事务一致性的两阶段提交协议"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-mysql事务-三个日志-分布式事务一致性的两阶段提交协议"}},[_._v("#")]),_._v(" 6.MySQL事务，三个日志，分布式事务一致性的两阶段提交协议")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("undo log（回滚日志）")]),_._v("：是 Innodb 存储引擎层生成的日志，实现了事务中的"),v("strong",[_._v("原子性")]),_._v("，主要"),v("strong",[_._v("用于事务回滚和 MVCC")]),_._v("。")]),_._v(" "),v("li",[v("strong",[_._v("redo log（重做日志）")]),_._v("：是 Innodb 存储引擎层生成的日志，实现了事务中的"),v("strong",[_._v("持久性")]),_._v("，主要"),v("strong",[_._v("用于掉电等故障恢复")]),_._v("；")]),_._v(" "),v("li",[v("strong",[_._v("binlog （归档日志）")]),_._v("：是 Server 层生成的日志，主要"),v("strong",[_._v("用于数据备份和主从复制")]),_._v("；")])]),_._v(" "),v("p",[_._v("undo log 是一种用于撤销回退的日志。在事务"),v("strong",[_._v("没提交之前")]),_._v("，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。")]),_._v(" "),v("p",[_._v("undo log 是如何刷盘（持久化到磁盘）的？")]),_._v(" "),v("p",[_._v("undo log 和数据页的刷盘策略是一样的，都需要通过 redo log 保证持久化。")]),_._v(" "),v("p",[v("strong",[_._v("buffer pool 中有 undo 页，对 undo 页的修改也都会记录到 redo log")]),_._v("。"),v("strong",[_._v("在内存修改该 Undo 页面后，需要记录对应的 redo log")]),_._v("。"),v("strong",[_._v("redo log 会每秒刷盘，提交事务时也会刷盘（redo log刷盘策略）****，数据页和 undo 页都是靠这个机制保证持久化的")]),_._v("。")]),_._v(" "),v("p",[_._v("redo log：")]),_._v(" "),v("p",[_._v("Buffer Pool 是提高了读写效率没错，但是问题来了，Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。")]),_._v(" "),v("p",[_._v("为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，"),v("strong",[_._v("这个时候更新就算完成了")]),_._v("。")]),_._v(" "),v("p",[_._v("后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 "),v("strong",[_._v("WAL （Write-Ahead Logging）技术")]),_._v("。")]),_._v(" "),v("p",[v("strong",[_._v("WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上")]),_._v("。")]),_._v(" "),v("p",[_._v("redo log 是物理日志，记录了某个数据页做了什么修改，比如"),v("strong",[_._v("对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新")]),_._v("，每当执行一个事务就会产生这样的一条或者多条物理日志。")]),_._v(" "),v("p",[_._v("在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。")]),_._v(" "),v("p",[_._v("当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。")]),_._v(" "),v("p",[v("strong",[_._v("为什么需要两阶段提交")])]),_._v(" "),v("p",[_._v("事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。")]),_._v(" "),v("p",[_._v("举个例子，假设 id = 1 这行数据的字段 name 的值原本是 'jay'，然后执行 "),v("code",[_._v("UPDATE t_user SET name = 'xiaolin' WHERE id = 1;")]),_._v(" 如果在持久化 redo log 和 binlog 两个日志的过程中，出现了半成功状态，那么就有两种情况：")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入")]),_._v("。MySQL 重启后，通过 redo log 能将 Buffer Pool 中 id = 1 这行数据的 name 字段恢复到新值 xiaolin，但是 binlog 里面没有记录这条更新语句，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行 name 字段是旧值 jay，与主库的值不一致性；")]),_._v(" "),v("li",[v("strong",[_._v("如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入")]),_._v("。由于 redo log 还没写，崩溃恢复以后这个事务无效，所以 id = 1 这行数据的 name 字段还是旧值 jay，而 binlog 里面记录了这条更新语句，在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，那么这一行 name 字段是新值 xiaolin，与主库的值不一致性；")])]),_._v(" "),v("p",[_._v("可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。")]),_._v(" "),v("p",[v("strong",[_._v("MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决")]),_._v("，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。")]),_._v(" "),v("p",[v("strong",[_._v("两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」")]),_._v("，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段。")]),_._v(" "),v("p",[_._v("MySQL事务提交过程将redo log的写入拆分成两个步骤，prepare和commit，中间穿插binlog的罗盘操作")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("prepare 阶段")]),_._v("：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；")]),_._v(" "),v("li",[v("strong",[_._v("commit 阶段")]),_._v("：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功")])]),_._v(" "),v("p",[v("strong",[_._v("两阶段提交是以 binlog 写成功为事务提交成功的标识")]),_._v("，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。")]),_._v(" "),v("blockquote",[v("p",[_._v("处于 prepare 阶段的 redo log 加上完整 binlog，重启就提交事务，MySQL 为什么要这么设计?")])]),_._v(" "),v("p",[_._v("binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。")]),_._v(" "),v("p",[_._v("所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。")]),_._v(" "),v("blockquote",[v("p",[_._v("事务没提交的时候，redo log 会被持久化到磁盘吗？")])]),_._v(" "),v("p",[_._v("会的。")]),_._v(" "),v("p",[_._v("redo log 可以在事务没提交之前持久化到磁盘，但是 binlog 必须在事务提交之后，才可以持久化到磁盘。")]),_._v(" "),v("h3",{attrs:{id:"_7-mysql和redis的刷盘策略比较"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_7-mysql和redis的刷盘策略比较"}},[_._v("#")]),_._v(" 7.MySQL和Redis的刷盘策略比较")]),_._v(" "),v("p",[v("strong",[_._v("MySQL的redo log刷盘策略：")])]),_._v(" "),v("p",[_._v("缓存在 redo log buffer 里的 redo log 还是在内存中，它什么时候刷新到磁盘？")]),_._v(" "),v("p",[_._v("主要有下面几个时机：")]),_._v(" "),v("ul",[v("li",[_._v("MySQL 正常关闭时；")]),_._v(" "),v("li",[_._v("当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；")]),_._v(" "),v("li",[_._v("InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。")]),_._v(" "),v("li",[v("strong",[_._v("每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘")]),_._v("（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。和两阶段提交协议公用，先写redo log，redo log变成prepare状态，再写bin log binlog落盘完成后，变成commit状态。可以通过bin log和redo log里面事务的ID，区别事务是否完成提交。")])]),_._v(" "),v("p",[_._v("上面这种 redo log 刷盘时机是在事务提交的时候，这个默认的行为。")]),_._v(" "),v("p",[_._v("除此之外，InnoDB 还提供了另外两种策略，由参数 "),v("code",[_._v("innodb_flush_log_at_trx_commit")]),_._v(" 参数控制，可取的值有：0、1、2，默认值为 1，这三个值分别代表的策略如下：")]),_._v(" "),v("ul",[v("li",[_._v("当设置该"),v("strong",[_._v("参数为 0 时")]),_._v("，表示每次事务提交时 ，还是"),v("strong",[_._v("将 redo log 留在 redo log buffer 中")]),_._v(" ，该模式下在事务提交时不会主动触发写入磁盘的操作。")]),_._v(" "),v("li",[_._v("当设置该"),v("strong",[_._v("参数为 1 时")]),_._v("，表示每次事务提交时，都"),v("strong",[_._v("将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘")]),_._v("，这样可以保证 MySQL 异常重启之后数据不会丢失。")]),_._v(" "),v("li",[_._v("当设置该"),v("strong",[_._v("参数为 2 时")]),_._v("，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log "),v("strong",[_._v("写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘")]),_._v("，因为操作系统的文件系统中有个 Page Cache（如果你想了解 Page Cache，可以看"),v("a",{attrs:{href:"https://xiaolincoding.com/os/6_file_system/pagecache.html",target:"_blank",rel:"noopener noreferrer"}},[_._v("这篇 (opens new window)"),v("OutboundLink")],1),_._v("），Page Cache 是专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存。")])]),_._v(" "),v("p",[v("strong",[_._v("MySQL中binlog什么时候刷盘")])]),_._v(" "),v("p",[_._v("事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。")]),_._v(" "),v("p",[_._v("一个事务的 binlog 是不能被拆开的，因此无论这个事务有多大（比如有很多条语句），也要保证一次性写入。这是因为有一个线程只能同时有一个事务在执行的设定，所以每当执行一个 begin/start transaction 的时候，就会默认提交上一个事务，这样如果一个事务的 binlog 被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破坏了原子性，是有问题的。")]),_._v(" "),v("blockquote",[v("p",[_._v("什么时候 binlog cache 会写到 binlog 文件？")])]),_._v(" "),v("p",[_._v("在事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 文件中，并清空 binlog cache。")]),_._v(" "),v("p",[_._v("​\t"),v("strong",[_._v("Redis AOF")]),_._v("：先执行命令，再写入AOF日志：Reids 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("避免额外的检查开销")]),_._v("：因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。")]),_._v(" "),v("li",[v("strong",[_._v("不会阻塞当前写操作命令的执行")]),_._v("：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。")])]),_._v(" "),v("p",[_._v("当然，这样做也会带来风险：")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("数据可能会丢失：")]),_._v(" 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。")]),_._v(" "),v("li",[v("strong",[_._v("可能阻塞其他操作：")]),_._v(" 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。")])]),_._v(" "),v("p",[_._v("**AOF写回策略：**redis写入AOF日志过程")]),_._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.xiaolincoding.com//mysql/other/4eeef4dd1bedd2ffe0b84d4eaa0dbdea-20230309232249413.png",alt:"4eeef4dd1bedd2ffe0b84d4eaa0dbdea-20230309232249413"}})]),_._v(" "),v("ol",[v("li",[_._v("Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区；")]),_._v(" "),v("li",[_._v("然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；")]),_._v(" "),v("li",[_._v("具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。")])]),_._v(" "),v("p",[v("strong",[_._v("AOF文件的刷盘策略")]),_._v("：Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。 在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("Always")]),_._v("，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；")]),_._v(" "),v("li",[v("strong",[_._v("Everysec")]),_._v("，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；")]),_._v(" "),v("li",[v("strong",[_._v("No")]),_._v("，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。")])]),_._v(" "),v("p",[_._v("redis的刷盘")]),_._v(" "),v("p",[_._v("我也把这 3 个写回策略的优缺点总结成了一张表格：")]),_._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.xiaolincoding.com//mysql/other/98987d9417b2bab43087f45fc959d32a-20230309232253633.png",alt:"img"}})]),_._v(" "),v("p",[_._v("redis AOF重写机制中，子进程读取AOF文件时，主进程对AOF文件有修改，AOF文件发生写时复制，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？")]),_._v(" "),v("p",[_._v("为了解决这种数据不一致问题，Redis 设置了一个 "),v("strong",[_._v("AOF 重写缓冲区")]),_._v("，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。")]),_._v(" "),v("p",[_._v("在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会"),v("strong",[_._v("同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」")]),_._v("。")]),_._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309232301042.png",alt:"img"}})]),_._v(" "),v("p",[_._v("也就是说，在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:")]),_._v(" "),v("ul",[v("li",[_._v("执行客户端发来的命令；")]),_._v(" "),v("li",[_._v("将执行后的写命令追加到 「AOF 缓冲区」；")]),_._v(" "),v("li",[_._v("将执行后的写命令追加到 「AOF 重写缓冲区」；")])]),_._v(" "),v("p",[v("strong",[_._v("RDB 做快照时会阻塞线程吗？")])]),_._v(" "),v("p",[_._v("Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：")]),_._v(" "),v("ul",[v("li",[_._v("执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，"),v("strong",[_._v("会阻塞主线程")]),_._v("；")]),_._v(" "),v("li",[_._v("执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以"),v("strong",[_._v("避免主线程的阻塞")]),_._v("；")])]),_._v(" "),v("p",[_._v("Redis 还可以通过配置文件的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置：")]),_._v(" "),v("div",{staticClass:"language-c extra-class"},[v("pre",{pre:!0,attrs:{class:"language-c"}},[v("code",[_._v("save "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("900")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),_._v("\nsave "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("300")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("10")]),_._v("\nsave "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("60")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("10000")]),_._v("\n")])])]),v("p",[_._v("Redis 的快照是"),v("strong",[_._v("全量快照")]),_._v("，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。")]),_._v(" "),v("blockquote",[v("p",[_._v("RDB 在执行快照的时候，数据能修改吗？")])]),_._v(" "),v("p",[_._v("可以的，执行 bgsave 过程中，Redis 依然"),v("strong",[_._v("可以继续处理操作命令")]),_._v("的，也就是数据是能被修改的，关键的技术就在于"),v("strong",[_._v("写时复制技术（Copy-On-Write, COW）。")])]),_._v(" "),v("p",[_._v("执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。")]),_._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.xiaolincoding.com//mysql/other/c34a9d1f58d602ff1fe8601f7270baa7-20230309232304226.png",alt:"img"}})]),_._v(" "),v("p",[_._v("如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。")]),_._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.xiaolincoding.com//mysql/other/ebd620db8a1af66fbeb8f4d4ef6adc68-20230309232308604.png",alt:"img"}})]),_._v(" "),v("h3",{attrs:{id:"_8-mysql与redis-的主从复制比较"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_8-mysql与redis-的主从复制比较"}},[_._v("#")]),_._v(" 8.MySQL与Redis 的主从复制比较")]),_._v(" "),v("p",[v("strong",[_._v("Redis主从复制")])]),_._v(" "),v("p",[_._v("主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。")]),_._v(" "),v("p",[_._v("主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。")]),_._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.xiaolincoding.com//mysql/other/2b7231b6aabb9a9a2e2390ab3a280b2d.png",alt:"img"}})]),_._v(" "),v("p",[_._v("也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。")]),_._v(" "),v("p",[_._v("注意，主从服务器之间的命令复制是"),v("strong",[_._v("异步")]),_._v("进行的。")]),_._v(" "),v("p",[_._v("具体来说，在主从服务器命令传播阶段，主服务器收到新的写命令后，会发送给从服务器。但是，主服务器并不会等到从服务器实际执行完命令后，再把结果返回给客户端，而是主服务器自己在本地执行完命令后，就会向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器间的数据就不一致了。")]),_._v(" "),v("p",[_._v("所以，无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的。")]),_._v(" "),v("p",[v("strong",[_._v("MySQL的主从复制")])]),_._v(" "),v("p",[_._v("MySQL 集群的主从复制过程梳理成 3 个阶段：")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("写入 Binlog")]),_._v("：主库写 binlog 日志，提交事务，并更新本地存储数据。")]),_._v(" "),v("li",[v("strong",[_._v("同步 Binlog")]),_._v("：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。")]),_._v(" "),v("li",[v("strong",[_._v("回放 Binlog")]),_._v("：回放 binlog，并更新存储引擎中的数据。")])]),_._v(" "),v("p",[_._v("具体详细过程如下：")]),_._v(" "),v("ul",[v("li",[_._v("MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。")]),_._v(" "),v("li",[_._v("从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。")]),_._v(" "),v("li",[_._v("从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。")])]),_._v(" "),v("h3",{attrs:{id:"_9-缓存更新问题-以及缓存一执行问题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_9-缓存更新问题-以及缓存一执行问题"}},[_._v("#")]),_._v(" 9.缓存更新问题，以及缓存一执行问题")]),_._v(" "),v("h3",{attrs:{id:"_10-mysql-inondb中的buffer-pool"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_10-mysql-inondb中的buffer-pool"}},[_._v("#")]),_._v(" 10.MySQL Inondb中的Buffer pool")]),_._v(" "),v("p",[_._v("当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，"),v("strong",[_._v("通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录")]),_._v("。将页加载到 Buffer Pool 后，再通过页里的"),v("strong",[_._v("页目录去定位到某条具体的记录")]),_._v("。")]),_._v(" "),v("p",[_._v("buffer pool中的数据结构：")]),_._v(" "),v("p",[_._v("Free 链表：空闲链表-管理空闲的内存块")]),_._v(" "),v("p",[_._v("Flush链表：链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘")]),_._v(" "),v("p",[v("strong",[_._v("如何提高缓存命中率？")])]),_._v(" "),v("p",[_._v("Buffer Pool 的大小是有限的，对于一些频繁访问的数据我们希望可以一直留在 Buffer Pool 中，而一些很少访问的数据希望可以在某些时机可以淘汰掉，从而保证 Buffer Pool 不会因为满了而导致无法再缓存新的数据，同时还能保证常用数据留在 Buffer Pool 中。")]),_._v(" "),v("p",[_._v("要实现这个，最容易想到的就是 LRU（Least recently used）算法。")]),_._v(" "),v("p",[_._v("该算法的思路是，链表头部的节点是最近使用的，而链表末尾的节点是最久没被使用的。那么，当空间不够了，就淘汰最久没被使用的节点，从而腾出空间。")]),_._v(" "),v("p",[_._v("简单的 LRU 算法的实现思路是这样的：")]),_._v(" "),v("ul",[v("li",[_._v("当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。")]),_._v(" "),v("li",[_._v("当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点。")])]),_._v(" "),v("p",[_._v("Buffer pool中有三种页和链表来管理数据：")]),_._v(" "),v("ul",[v("li",[_._v("Free Page（空闲页），表示此页未被使用，位于 Free 链表；")]),_._v(" "),v("li",[_._v("Clean Page（干净页），表示此页已被使用，但是页面未发生修改，位于LRU 链表。")]),_._v(" "),v("li",[_._v("Dirty Page（脏页），表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。脏页同时存在于 LRU 链表和 Flush 链表。")])]),_._v(" "),v("p",[_._v("简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题：")]),_._v(" "),v("ul",[v("li",[_._v("预读失效；")]),_._v(" "),v("li",[_._v("Buffer Pool 污染；")])]),_._v(" "),v("blockquote",[v("p",[_._v("什么是 Buffer Pool 污染？")])]),_._v(" "),v("p",[_._v("当某一个 SQL 语句"),v("strong",[_._v("扫描了大量的数据")]),_._v("时，在 Buffer Pool 空间比较有限的情况下，可能会将 "),v("strong",[_._v("Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了")]),_._v("，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 "),v("strong",[_._v("Buffer Pool 污染")]),_._v("。")]),_._v(" "),v("h3",{attrs:{id:"_11-mysql在可重复读隔离级别下的加锁规则"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_11-mysql在可重复读隔离级别下的加锁规则"}},[_._v("#")]),_._v(" 11.MySQL在可重复读隔离级别下的加锁规则")]),_._v(" "),v("p",[_._v("主要是next-key是一个前开后闭的锁，所以>=x的时候如果x存在，至少会生成两个锁，一个记录锁x，一个next-key（x,正无穷），实际上更可能是一段一段的next-key，最后一个是左开右开的间隙锁")]),_._v(" "),v("p",[_._v("1.唯一索引的等值查询：值存在（记录锁），值不存在（间隙锁）")]),_._v(" "),v("p",[_._v("2.唯一索引范围查询：范围查询和等值查询的加锁规则是不同的。")]),_._v(" "),v("p",[_._v("当唯一索引进行范围查询时，"),v("strong",[_._v("会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁")]),_._v("：")]),_._v(" "),v("p",[_._v("3.非唯一索引等值查询：当我们用非唯一索引进行等值查询的时候，"),v("strong",[_._v("因为存在两个索引，一个是主键索引，一个是非唯一索引（二级索引），所以在加锁时，同时会对这两个索引都加锁，但是对主键索引加锁的时候，只有满足查询条件的记录才会对它们的主键索引加锁")]),_._v("。")]),_._v(" "),v("p",[_._v("针对非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同：")]),_._v(" "),v("ul",[v("li",[_._v("当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是"),v("strong",[_._v("非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁")]),_._v("。")]),_._v(" "),v("li",[_._v("当查询的记录「不存在」时，"),v("strong",[_._v("扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁")]),_._v("。")])]),_._v(" "),v("p",[_._v("4.非唯一索引范围查询")]),_._v(" "),v("p",[_._v("非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于"),v("strong",[_._v("非唯一索引范围查询，索引的 next-key lock 不会有退化为间隙锁和记录锁的情况")]),_._v("，也就是非唯一索引进行范围查询时，对二级索引记录加锁都是加 next-key 锁。")]),_._v(" "),v("p",[v("strong",[_._v("插入意向锁是一种特殊的间隙锁，但不同于间隙锁的是，该锁只用于并发插入操作")]),_._v("。")]),_._v(" "),v("p",[_._v("如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。")]),_._v(" "),v("p",[_._v("插入意向锁与间隙锁的另一个非常重要的差别是："),v("strong",[_._v("尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。所以，插入意向锁和间隙锁之间是冲突的")]),_._v("。")]),_._v(" "),v("p",[_._v("另外，我补充一点，插入意向锁的生成时机：")]),_._v(" "),v("ul",[v("li",[_._v("每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，此时会生成一个插入意向锁，然后锁的状态设置为等待状态（"),v("em",[_._v("PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁")]),_._v("），现象就是 Insert 语句会被阻塞。")])]),_._v(" "),v("p",[v("strong",[_._v("没有加索引的查询")])]),_._v(" "),v("p",[_._v("前面的案例，我们的查询语句都有使用索引查询，也就是查询记录的时候，是通过索引扫描的方式查询的，然后对扫描出来的记录进行加锁。")]),_._v(" "),v("p",[v("strong",[_._v("如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞")]),_._v("。")]),_._v(" "),v("p",[_._v("不只是锁定读查询语句不加索引才会导致这种情况，update 和 delete 语句如果查询条件不加索引，那么由于扫描的方式是全表扫描，于是就会对每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表。")]),_._v(" "),v("p",[_._v("因此，"),v("strong",[_._v("在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了")]),_._v("，这是挺严重的问题。")]),_._v(" "),v("p",[_._v("在 InnoDB 事务中，对记录加锁带基本单位是 next-key 锁，但是会因为一些条件会退化成间隙锁，或者记录锁。加锁的位置准确的说，"),v("strong",[_._v("锁是加在索引上的而非行上")]),_._v("。")]),_._v(" "),v("p",[_._v("Innodb 源码里面在扫描记录的时候，都是针对索引项这个单位去加锁的， update 不带索引就是全表扫扫描，也就是表里的索引项都加锁，相当于锁了整张表，所以大家误以为加了表锁。")]),_._v(" "),v("h3",{attrs:{id:"_12-mysql死锁的例子"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_12-mysql死锁的例子"}},[_._v("#")]),_._v(" 12.MySQL死锁的例子")]),_._v(" "),v("p",[_._v("数据表中的数据")]),_._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.xiaolincoding.com//mysql/other/54fc00f9f87a60ab7b5ba92d824a892d.png",alt:"54fc00f9f87a60ab7b5ba92d824a892d"}})]),_._v(" "),v("p",[_._v("假设这时有两事务，一个事务要插入订单 1007 ，另外一个事务要插入订单 1008，因为需要对订单做幂等性校验，所以两个事务先要查询该订单是否存在，不存在才插入记录，过程如下：")]),_._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.xiaolincoding.com//mysql/other/90c1e01d0345de639e3426cea0390e80.png",alt:"img"}})]),_._v(" "),v("p",[_._v("死锁原因：SELECT for update会获取间隙锁（或者record，next-key锁）这里在查询记录是否存在的时候，使用了 "),v("code",[_._v("select ... for update")]),_._v(" 语句，目的为了防止事务执行的过程中，有其他事务插入了记录，而出现幻读的问题。事务A获得了间隙锁（1006，正无穷），同样事务B也获得了间隙锁（1006，正无穷），"),v("strong",[_._v("间隙锁之间是可以同时持有的")]),_._v("；")]),_._v(" "),v("p",[_._v("当事务 B 往事务 A next-key 锁的范围 (1006, +∞] 里插入 id = 1008 的记录就会被锁住：")]),_._v(" "),v("div",{staticClass:"language-sql extra-class"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("Insert")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("into")]),_._v(" t_order "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("order_no"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" create_date"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("values")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1008")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("now")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n")])])]),v("p",[_._v("因为当我们执行以下插入语句时，会在插入间隙上获取插入意向锁，"),v("strong",[_._v("而插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以所以两个事务中 "),v("code",[_._v("select ... for update")]),_._v(" 语句并不会相互影响")]),_._v("。")]),_._v(" "),v("p",[_._v("案例中的"),v("strong",[_._v("事务 A 和事务 B 在执行完后 "),v("code",[_._v("select ... for update")]),_._v(" 语句后都持有范围为"),v("code",[_._v("(1006,+∞]")]),_._v("的next-key 锁")]),_._v("，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，导致死锁。")]),_._v(" "),v("p",[v("strong",[_._v("间隙锁的意义只在于阻止区间被插入")]),_._v("，因此是可以共存的。"),v("strong",[_._v("一个事务获取的间隙锁不会阻止另一个事务获取同一个间隙范围的间隙锁")]),_._v("，共享和排他的间隙锁是没有区别的，他们相互不冲突，且功能相同，即两个事务可以同时持有包含共同间隙的间隙锁。")]),_._v(" "),v("p",[_._v("注意：（间隙锁与next-key锁的区别）")]),_._v(" "),v("p",[_._v("但是有一点要注意，"),v("strong",[_._v("next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的")]),_._v("。")]),_._v(" "),v("p",[_._v("比如，一个事务持有了范围为 (1, 10] 的 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，就会被阻塞。")]),_._v(" "),v("p",[_._v("虽然相同范围的间隙锁是多个事务相互兼容的，但对于记录锁，我们是要考虑 X 型与 S 型关系。X 型的记录锁与 X 型的记录锁是冲突的，比如一个事务执行了 select ... where id = 1 for update，后一个事务在执行这条语句的时候，就会被阻塞的。")]),_._v(" "),v("p",[_._v("但是还要注意！对于这种范围为 (1006, +∞] 的 next-key lock，两个事务是可以同时持有的，不会冲突。因为 +∞ 并不是一个真实的记录，自然就不需要考虑 X 型与 S 型关系。")]),_._v(" "),v("p",[v("strong",[_._v("插入语句的主键或者唯一索引冲突：")])]),_._v(" "),v("p",[_._v("insert语句插入已经存在的主键索引或者唯一索引，这个主键索引或者唯一索引会被加上Shared型的记录锁，因为会先查询这个主键或者唯一索引存不存在，相当于提前做一个主键或者唯一索引的等值查询。")]),_._v(" "),v("p",[v("strong",[_._v("MySQL如何避免死锁")])]),_._v(" "),v("p",[_._v("死锁的四个必要条件："),v("strong",[_._v("互斥、占有且等待、不可强占用、循环等待")]),_._v("。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。")]),_._v(" "),v("p",[_._v("在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：")]),_._v(" "),v("p",[v("strong",[_._v("设置事务等待锁的超时时间")]),_._v("。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 "),v("code",[_._v("innodb_lock_wait_timeout")]),_._v(" 是用来设置超时时间的，默认值时 50 秒。")]),_._v(" "),v("p",[v("strong",[_._v("开启主动死锁检测")]),_._v("。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 "),v("code",[_._v("innodb_deadlock_detect")]),_._v(" 设置为 on，表示开启这个逻辑，默认就开启。")]),_._v(" "),v("h3",{attrs:{id:"_13-mysql中事务的acid特性分别是由什么保证的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_13-mysql中事务的acid特性分别是由什么保证的"}},[_._v("#")]),_._v(" 13.MySQL中事务的ACID特性分别是由什么保证的")]),_._v(" "),v("p",[_._v("A：原子性：undolog")]),_._v(" "),v("p",[_._v("C：一致性：AID三者共同构成一致性")]),_._v(" "),v("p",[_._v("I：隔离性：由undolog和read view共同构成的MVCC保证")]),_._v(" "),v("p",[_._v("D：redolog保证持久化")]),_._v(" "),v("h3",{attrs:{id:"_14-indodb中数据是怎样存储的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_14-indodb中数据是怎样存储的"}},[_._v("#")]),_._v(" 14.INDODB中数据是怎样存储的")]),_._v(" "),v("p",[_._v("采用链表的结构是让数据页之间不需要是物理上的连续的，而是逻辑上的连续。")]),_._v(" "),v("p",[_._v("数据页的主要作用是存储记录，也就是数据库的数据，所以重点说一下数据页中的 User Records 是怎么组织数据的。")]),_._v(" "),v("p",[v("strong",[_._v("数据页中的记录按照「主键」顺序组成单向链表")]),_._v("，单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索。")]),_._v(" "),v("p",[_._v("因此，数据页中有一个"),v("strong",[_._v("页目录")]),_._v("，起到记录的索引作用，就像我们书那样，针对书中内容的每个章节设立了一个目录，想看某个章节的时候，可以查看目录，快速找到对应的章节的页数，而数据页中的页目录就是为了能快速找到记录。")]),_._v(" "),v("h3",{attrs:{id:"_15-数据库和缓存如何让保证一致性"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_15-数据库和缓存如何让保证一致性"}},[_._v("#")]),_._v(" 15."),v("a",{attrs:{href:"http://kaito-kidd.com/2021/09/08/how-to-keep-cache-and-consistency-of-db/",target:"_blank",rel:"noopener noreferrer"}},[_._v("数据库和缓存如何让保证一致性"),v("OutboundLink")],1)]),_._v(" "),v("ul",[v("li",[_._v("到底是更新缓存还是删缓存？")]),_._v(" "),v("li",[_._v("到底选择先更新数据库，再删除缓存，还是先删除缓存，再更新数据库？")]),_._v(" "),v("li",[_._v("为什么要引入消息队列保证一致性？")]),_._v(" "),v("li",[_._v("延迟双删会有什么问题？到底要不要用？")])]),_._v(" "),v("p",[_._v("消息队列」最为合适。这是因为消息队列的特性，正好符合我们的需求：")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("消息队列保证可靠性")]),_._v("：写到队列中的消息，成功消费之前不会丢失（重启项目也不担心）")]),_._v(" "),v("li",[v("strong",[_._v("消息队列保证消息成功投递")]),_._v("：下游从队列拉取消息，成功消费后才会删除消息，否则还会继续投递消息给消费者（符合我们重试的需求）")])]),_._v(" "),v("p",[_._v("那如果你确实不想在应用中去写消息队列，是否有更简单的方案，同时又可以保证一致性呢？")]),_._v(" "),v("p",[_._v("方案还是有的，这就是近几年比较流行的解决方案："),v("strong",[_._v("订阅数据库变更日志，再操作缓存")]),_._v("。")]),_._v(" "),v("p",[_._v("具体来讲就是，我们的业务应用在修改数据时，「只需」修改数据库，无需操作缓存。")]),_._v(" "),v("p",[_._v("那什么时候操作缓存呢？这就和数据库的「变更日志」有关了。")]),_._v(" "),v("p",[_._v("拿 MySQL 举例，当一条数据发生修改时，MySQL 就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。")]),_._v(" "),v("p",[v("strong",[_._v("推荐采用「先更新数据库，再删除缓存」方案，并配合「消息队列」或「订阅变更日志」的方式来做")]),_._v("。")]),_._v(" "),v("p",[v("strong",[_._v("延迟双删机制")])]),_._v(" "),v("p",[_._v("可以做到强一致吗？")]),_._v(" "),v("p",[_._v("看到这里你可能会想，这些方案还是不够完美，我就想让缓存和数据库「强一致」，到底能不能做到呢？")]),_._v(" "),v("p",[_._v("其实很难。")]),_._v(" "),v("p",[_._v("要想做到强一致，最常见的方案是 2PC、3PC、Paxos、Raft 这类一致性协议，但它们的性能往往比较差，而且这些方案也比较复杂，还要考虑各种容错问题。")]),_._v(" "),v("p",[_._v("相反，这时我们换个角度思考一下，我们引入缓存的目的是什么？")]),_._v(" "),v("p",[_._v("没错，"),v("strong",[_._v("性能")]),_._v("。")]),_._v(" "),v("p",[_._v("所以如果非要追求强一致，那必须要求所有更新操作完成之前期间，不能有「任何请求」进来。")]),_._v(" "),v("p",[_._v("虽然我们可以通过加「分布锁」的方式来实现，但我们也要付出相应的代价，甚至很可能会超过引入缓存带来的性能提升。")]),_._v(" "),v("p",[v("strong",[_._v("总结")])]),_._v(" "),v("p",[_._v("好了，总结一下这篇文章的重点。")]),_._v(" "),v("p",[_._v("1、想要提高应用的性能，可以引入「缓存」来解决")]),_._v(" "),v("p",[_._v("2、引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」")]),_._v(" "),v("p",[_._v("3、更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，解决方案是加「分布锁」，但这种方案存在「缓存资源浪费」和「机器性能浪费」的情况")]),_._v(" "),v("p",[_._v("4、采用「先删除缓存，再更新数据库」方案，在「并发」场景下依旧有不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估")]),_._v(" "),v("p",[_._v("5、采用「先更新数据库，再删除缓存」方案，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据最终一致")]),_._v(" "),v("p",[_._v("6、采用「先更新数据库，再删除缓存」方案，「读写分离 + 主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率")])])}),[],!1,null,null,null);v.default=r.exports}}]);